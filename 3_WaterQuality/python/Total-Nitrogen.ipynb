{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Monitoring - Exploratory Data Analysis\n",
    "```L. Patterson & John Fay\n",
    "Spring 2018```\n",
    "\n",
    "In this notebook, we examine the two datsets generated from our query of the [Water Quality Data portal](https://www.waterqualitydata.us/portal/) for nutrient data in HUC 03030002 from 1970 trough 2017. The first dataset ([sites.csv](https://www.waterqualitydata.us/Station/search?countrycode=US&statecode=US%3A37&siteType=Lake%2C%20Reservoir%2C%20Impoundment&siteType=Stream&huc=03030002&sampleMedia=Water&characteristicType=Nutrient&minresults=500&startDateLo=01-01-1970&startDateHi=12-31-2017&mimeType=csv&zip=yes&sorted=no)) contains data on the locations where samples were collected, and the second dataset ([results.csv](https://www.waterqualitydata.us/Result/search?countrycode=US&statecode=US%3A37&siteType=Lake%2C%20Reservoir%2C%20Impoundment&siteType=Stream&huc=03030002&sampleMedia=Water&characteristicType=Nutrient&minresults=500&startDateLo=01-01-1970&startDateHi=12-31-2017&mimeType=csv&zip=yes&sorted=no)) contains data on the nutrient samples collected at these sites. \n",
    "\n",
    "Our goals here are to upload, prepare (tidy, explore, and merge) these data, and ultimately provide some visualizations that reveal the state of water quality in Jordan lake. We'll begin with the **sites** dataset, examining a few attributes about these data, and the move to the **results** where we filter our data for 'clean' records and tidy it for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import folium\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Enable notebook plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and analyzie the water quality *sites* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data in as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data into the 'sites' dataframe \n",
    "sites = pd.read_csv('../data/station.csv',\n",
    "                   dtype={'HUCEightDigitCode':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the dimensions of the data frame\n",
    "sites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the columns and their data types\n",
    "sites.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data: Plot the sites\n",
    "Plot a map to see where water quality data were present from this portal.<br> First we'll plot all the points, then we'll remove sites with small drainage areas and see how many remain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all sites--\n",
    "\n",
    "#Find center coordinates from medians of lat and long columns\n",
    "medLat = sites['LatitudeMeasure'].median()\n",
    "medLng = sites['LongitudeMeasure'].median()\n",
    "\n",
    "#Create the initial map\n",
    "m = folium.Map(location=[medLat,medLng],\n",
    "               zoom_start=9,\n",
    "               tiles='stamenterrain')\n",
    "\n",
    "#Loop through all features and add them to the map as markers\n",
    "for row in sites.itertuples():\n",
    "    #Get info for the record\n",
    "    lat = row.LatitudeMeasure\n",
    "    lng = row.LongitudeMeasure\n",
    "    name = row.MonitoringLocationName\n",
    "    #Create the marker object, adding them to the map object\n",
    "    folium.CircleMarker(location=[lat,lng],\n",
    "                        popup=name,\n",
    "                        color='red',\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.6,\n",
    "                        radius=3,\n",
    "                        stroke=False).add_to(m)\n",
    "    \n",
    "#Show map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sites with an area > 25 sq mi\n",
    "sites2 = sites[sites['DrainageAreaMeasure/MeasureValue'] > 25]\n",
    "sites2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Only 10 records!* This seems small. Let's plot these in blue on top of the map created above to see where these 10 sites occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through all features and add them to the map as markers\n",
    "for row in sites2.itertuples():\n",
    "    #Get info for the record\n",
    "    lat = row.LatitudeMeasure\n",
    "    lng = row.LongitudeMeasure\n",
    "    name = row.MonitoringLocationName\n",
    "    #Create the marker object, adding them to the map object\n",
    "    folium.CircleMarker(location=[lat,lng],\n",
    "                        popup=name,\n",
    "                        color='blue',\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.8,\n",
    "                        radius=3,\n",
    "                        stroke=False).add_to(m)\n",
    "    \n",
    "#Show map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a closer look at the drainage measurement values and see there are numerous `NA` values. *Clearly, filtering by drainage area will not work*. The main point I want to make here is <mark>**don’t be afraid to play with the data.**</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s replot the site map but now change the popup name to see which site names are located within each branch of Jordan Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the map\n",
    "m = folium.Map(location=[medLat,medLng],\n",
    "               zoom_start=9,\n",
    "               tiles='stamenterrain')\n",
    "\n",
    "#Loop through all features and add them to the map as markers\n",
    "for row in sites.itertuples():\n",
    "    #Get info for the record\n",
    "    lat = row.LatitudeMeasure\n",
    "    lng = row.LongitudeMeasure\n",
    "    name = row.MonitoringLocationIdentifier #<-- Change the field to show as the popup\n",
    "    #Create the marker object, adding them to the map object\n",
    "    folium.CircleMarker(location=[lat,lng],\n",
    "                        popup=name,\n",
    "                        color='red',\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.6,\n",
    "                        radius=3,\n",
    "                        stroke=False).add_to(m)\n",
    "    \n",
    "#Show map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cull some unused columns from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepColumns = [0,2,3,7,8,11,12]\n",
    "sites = sites.iloc[:,keepColumns]\n",
    "sites.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import and explore the water quality *measurement* data\n",
    "The second dataset downloaded from the [Water Quality Data portal](https://www.waterqualitydata.us/portal/) were the water quality results, stored in the [`result.csv`](https://www.waterqualitydata.us/Result/search?countrycode=US&statecode=US%3A37&siteType=Lake%2C%20Reservoir%2C%20Impoundment&siteType=Stream&huc=03030002&sampleMedia=Water&characteristicType=Nutrient&minresults=500&startDateLo=01-01-1970&startDateHi=12-31-2017&mimeType=csv&zip=yes&sorted=no) file. Let's now import this \\[large\\] file and tidy it up for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the results.csv\n",
    "results = pd.read_csv('../data/result.csv',\n",
    "                      low_memory=False      #This is required as it's a large file...\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dimensions of the dataframe: it's BIG\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by filtering records to only the ones we want\n",
    "Once we load in the measurements data, we need to do some cleaning. The first step is to filter the data to what we want to use. For example,\n",
    "* We want to restrict our analysis to streams, filtering out all other media.<br><br>\n",
    "\n",
    "* We want to make sure we are using routine samples and not extreme event sampling (biased for specific occasions and not for estimating annual average load). So, we'd like to filter out events like storms, droughts, floods, and spring break ups from our analysis.<br><br>\n",
    "\n",
    "* We determine what type of Nitrogen we want to use. From the literature we found that regulations for Nitrogen include: nitrate, nitrite, ammonia and organic forms. Doing some reading about the WQX standards, you learn that Nitrogen, mixed froms incorporates all of the above forms of nitrogen.<br><br>\n",
    "\n",
    "*  We also want to make sure we are looking at *total nitrogen*, so we want to make sure the `Results Sample Fraction Text` only includes those with `Total`.\n",
    "\n",
    "It's handy to know the to what each field in our data refers and what it's values are. An easy way to inspect the latter is with the Pandas `unique()` function which lists the unique values found in a give column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the unique values inthe HydrologicEvent column\n",
    "results['HydrologicEvent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the unique values inthe CharacteristicName column\n",
    "results['CharacteristicName'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering in Pandas can be done by creating bitwise (i.e. True/False) \"mask\" and then combining them with logical operations.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 in filtering: creating a mask for each criteria\n",
    "mediaMask = results['ActivityMediaSubdivisionName'] == \"Surface Water\"\n",
    "hydroMask = ~results['HydrologicEvent'].isin((\"Storm\",\"Flood\",\"Spring breakup\",\"Drought\")) \n",
    "charMask = results['CharacteristicName'] == \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3)\"\n",
    "sampFracMask = results['ResultSampleFractionText'] == 'Total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 in filtering: Applying the masks using logical combinations\n",
    "nitrogen = results[mediaMask & hydroMask & charMask & sampFracMask] \n",
    "nitrogen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the filters worked\n",
    "nitrogen['ActivityMediaSubdivisionName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrogen['HydrologicEvent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrogen['CharacteristicName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrogen['ResultSampleFractionText'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset columns\n",
    "usecols=[0,6,21,30,31,32,33,34,58,59,60]\n",
    "nitrogen = nitrogen.iloc[:,usecols]\n",
    "nitrogen.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Limits and Unit Conversion\n",
    "You may have noticed that many sample sites state “not detected”. This is important data that are not currently being represented. Create a new column and set the value equal to the results, unless it is below the detection limit - in which case set it equal to ½ of the detection limit.\n",
    "\n",
    "You may also have noted that the total nitrogen was sometimes reported as mg/l or mg/l NO3. We want mg/l. To convert to mg/l, we know the atomic weight of nitrogen is 14.0067 and the molar mass of nitrate anion (NO3) is 62.0049 g/mole. Therefore, to convert between units:\n",
    "* Nitrate-N (mg/L) = 0.2259 x Nitrate-NO3 (mg/L)\n",
    "* Nitrate-NO3 (mg/L) = 4.4268 x Nitrate-N (mg/L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set data below the detection limit equal to 1/2 the detection limit\n",
    "\n",
    "#Set default values to the ResultMeasureValue\n",
    "nitrogen['TotalN'] = nitrogen['ResultMeasureValue']\n",
    "nitrogen['TotalN'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of values that are \"Not Detected\" and update those valuse\n",
    "ndMask = nitrogen['ResultDetectionConditionText'] == 'Not Detected'\n",
    "nitrogen.loc[ndMask,\"TotalN\"] = nitrogen['DetectionQuantitationLimitMeasure/MeasureValue'] / 2\n",
    "nitrogen['TotalN'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert mg/l as NO3 to mg/l as N\n",
    "no3Mask = nitrogen['DetectionQuantitationLimitMeasure/MeasureUnitCode'] == 'mg/l NO3'\n",
    "nitrogen.loc[no3Mask,'TotalN'] = nitrogen['TotalN'] * 0.2259"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our saved records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrogen.to_csv(\"../data/NResults.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge sites and measurements together\n",
    "Currently, site and measurement data are not connected together. However, we may want to show the nitrate values on a map. To do this, we merge the data together based on a unique identifier shared between the two data sets. In this case, it is the *MonitoringLocationIdentifier* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two datasets, joining the sites to the results (as sites may have >1 result) \n",
    "nitrodata = pd.merge(left=sites,\n",
    "                     right=nitrogen,\n",
    "                     how='right',\n",
    "                     on='MonitoringLocationIdentifier')\n",
    "nitrodata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the ActivityStartDate to a datetime object\n",
    "nitrodata['ActivityStartDate'] = pd.to_datetime(nitrodata['ActivityStartDate'],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create year values from the ActivityStartDate column\n",
    "nitrodata['Year'] = pd.DatetimeIndex(nitrodata['ActivityStartDate']).year\n",
    "nitrodata.groupby('Year')['Year'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create month categories from the ActivityStartDate column \n",
    "nitrodata['Month'] = pd.DatetimeIndex(nitrodata['ActivityStartDate']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrodata['Month'].plot(kind='hist',\n",
    "                        bins=12,\n",
    "                        figsize=(8,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter merged data\n",
    "\n",
    "First we want to know how many sites are collecting data of interest. We find there are 22 sites. Of those sites, we want to know which were collecting data after the Jordan Lake Rules were passed and how much data are being collected at this site.\n",
    "\n",
    "Based on this, we see several sites stopped collecting data prior to 2009, when the first iteration of Jordan Rules were passed. We also see that some of these sites collected only a few years of data. Remove those sites and plot the remaining sites on the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tally the number of unique sites\n",
    "nitrodata['MonitoringLocationIdentifier'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data by site\n",
    "siteGroup = nitrodata.groupby('MonitoringLocationIdentifier')\n",
    "\n",
    "#Compute min and max of year\n",
    "siteInfo = siteGroup.agg({'Year':('min','max')})\n",
    "\n",
    "#Rename Colummns\n",
    "siteInfo.columns = ['StartYear','EndYear']\n",
    "\n",
    "#Compute Range\n",
    "siteInfo['Range'] = siteInfo['EndYear'] - siteInfo['StartYear']\n",
    "siteInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limit data to those with more than 10 years data and still operating\n",
    "siteInfo = siteInfo.query('Range >= 10 & EndYear >= 2017')\n",
    "siteInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter our compined table to contain only these sites\n",
    "siteMask = nitrodata['MonitoringLocationIdentifier'].isin(siteInfo.index)\n",
    "df = nitrodata[siteMask]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group and map these sites\n",
    "df2 = df.groupby('MonitoringLocationIdentifier').first()\n",
    "\n",
    "#Find center coordinates from medians of lat and long columns\n",
    "medLat = df2['LatitudeMeasure'].median()\n",
    "medLng = df2['LongitudeMeasure'].median()\n",
    "\n",
    "#Create the initial map\n",
    "m = folium.Map(location=[medLat,medLng],\n",
    "               zoom_start=9,\n",
    "               tiles='stamenterrain')\n",
    "\n",
    "#Loop through all features and add them to the map as markers\n",
    "for row in df2.itertuples():\n",
    "    #Get info for the record\n",
    "    lat = row.LatitudeMeasure\n",
    "    lng = row.LongitudeMeasure\n",
    "    name = row.MonitoringLocationName\n",
    "    #Create the marker object, adding them to the map object\n",
    "    folium.CircleMarker(location=[lat,lng],\n",
    "                        popup=name,\n",
    "                        color='red',\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.8,\n",
    "                        radius=5,\n",
    "                        stroke=False).add_to(m)\n",
    "    \n",
    "#Show map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot total nitrogen over time\n",
    "\n",
    "### Plot the 2017 Nitrogen year on leaflet\n",
    "\n",
    "## Compare the Nitrogen Load with Thresholds\n",
    "The water quality data reports Nitrogen as mg/l. In order to convert to an annual load (lbs/yr), we need to know the volume of water flowing through each site. Go to the NWIS Mapper to find which USGS gauges are closest to the Haw River Arm (1 site) and the New Hope Arm (3 sites).\n",
    "\n",
    "### Load NWIS data for Haw River\n",
    "\n",
    "### Calculate Annual Load for Haw River\n",
    "\n",
    "To calculate the annual load we need to convert cfs to MGD. Then we use pipes and dplyr to calculate the total annual flow at Haw River. Next, we calculate the average Nitrogen load for samples taken during each year. This is a rough proxy. A finer analysis can be undertaken by summarizing monthly flow and water quality, aggregating to the year as the last step. The annual load is then the: Total Flow * average Nitrogen * 8.34 lbs per gallon\n",
    "\n",
    "We can then plot the annual load with the threshold of 2.567 Million pounds per year.\n",
    "\n",
    "### Calculate Annual Load for New Hope Creek\n",
    "\n",
    "Here there are 3 upstream gauges for New Hope Creek. We will download that information into a single file. We repeat the above analyis with the New Hope stream gauges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
